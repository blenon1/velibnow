{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83458767",
   "metadata": {},
   "source": [
    "# Fonctions d'obtention des données\n",
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbcb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from config import URL_HOLIDAYS, URL_SCHOOL, URL_METEO_HOURLY\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66032f0",
   "metadata": {},
   "source": [
    "## Class de lecture des données velib historiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd96b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VelibCsvReader:\n",
    "    def __init__(self):\n",
    "        self.file_path = \"./data/dataset/historique_stations.csv\"\n",
    "\n",
    "    def read_dataframe(self):\n",
    "        \"\"\"Combine status + info sur les stations\"\"\"\n",
    "        dataframe = pd.read_csv(\n",
    "            filepath_or_buffer=self.file_path,\n",
    "            sep=\",\"\n",
    "        )\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bfbf7c",
   "metadata": {},
   "source": [
    "## Class API pour données sur les vacances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01808ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HolidaysAPI:\n",
    "    \"\"\"\n",
    "    Récupération des jours fériés et des vacances scolaires françaises.\n",
    "    \"\"\"\n",
    "\n",
    "    def fetch_public_holidays(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            data = requests.get(URL_HOLIDAYS, timeout=10).json()\n",
    "            df = pd.DataFrame(list(data.items()), columns=[\"date\", \"holiday_name\"])\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Erreur API jours fériés : {e}\")\n",
    "\n",
    "    def fetch_school_vacations(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            data = requests.get(URL_SCHOOL, timeout=10).json()\n",
    "            results = data.get(\"results\", [])\n",
    "            df = pd.DataFrame(results)\n",
    "            if not df.empty:\n",
    "                df = df[[\"start_date\", \"end_date\", \"zones\", \"description\"]]\n",
    "                df[\"start_date\"] = pd.to_datetime(df[\"start_date\"])\n",
    "                df[\"end_date\"] = pd.to_datetime(df[\"end_date\"])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Erreur API vacances scolaires : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee9993",
   "metadata": {},
   "source": [
    "## Class API pour les données météo historiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7b4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "class WeatherCsvReader:\n",
    "    def __init__(self, file_path: str = \"./data/dataset/historical_meteo.csv\"):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "        # Mapping colonnes brutes -> colonnes standardisées\n",
    "        self.WEATHER_COL_MAP = {\n",
    "            \"AAAAMMJJHH\": \"timestamp\",\n",
    "            \"NUM_POSTE\":  \"station_id\",\n",
    "            \"NOM_USUEL\":  \"station_name\",\n",
    "            \"LAT\":        \"lat_deg\",\n",
    "            \"LON\":        \"lon_deg\",\n",
    "            \"ALTI\":       \"alt_m\",\n",
    "            \"RR1\":        \"precip_mm\",\n",
    "            \"DRR1\":       \"precip_dur_min\",\n",
    "            \"T\":          \"temp_c\",\n",
    "            \"TD\":         \"dewpoint_c\",\n",
    "            \"U\":          \"humidity_rel_pct\",\n",
    "            \"FF\":         \"wind_speed_10m_ms\",\n",
    "            \"DD\":         \"wind_dir_deg\",\n",
    "            \"FXI\":        \"wind_gust_10m_ms\",\n",
    "            \"PSTAT\":      \"pressure_hpa_station\",\n",
    "            \"PMER\":       \"pressure_hpa_sea\",\n",
    "\n",
    "            \"N\":          \"cloud_oktas\",\n",
    "            \"INS\":        \"insolation_min\",            # plan B si N absent\n",
    "            \"GLO\":        \"global_radiation_j_cm2\",    # plan B bis\n",
    "            \"WW\":         \"wmo_present_weather\",       # optionnel mais utile\n",
    "        }\n",
    "\n",
    "        # Schéma final (cible) — timestamp est parsé à part\n",
    "        self.WEATHER_DTYPES: Dict[str, str] = {\n",
    "            \"station_id\":          \"string\",\n",
    "            \"station_name\":        \"string\",\n",
    "            \"lat_deg\":             \"float64\",\n",
    "            \"lon_deg\":             \"float64\",\n",
    "            \"alt_m\":               \"Int64\",\n",
    "            \"timestamp\":           \"datetime64[ns]\",\n",
    "            \"precip_mm\":           \"float64\",\n",
    "            \"precip_dur_min\":      \"Int64\",\n",
    "            \"temp_c\":              \"float64\",\n",
    "            \"dewpoint_c\":          \"float64\",\n",
    "            \"humidity_rel_pct\":    \"float64\",\n",
    "            \"wind_speed_10m_ms\":   \"float64\",\n",
    "            \"wind_dir_deg\":        \"float64\",\n",
    "            \"wind_gust_10m_ms\":    \"float64\",\n",
    "            \"pressure_hpa\":        \"float64\",\n",
    "            \n",
    "            \"cloud_oktas\":   \"float64\",\n",
    "            \"insolation_min\":        \"float64\",\n",
    "            \"global_radiation_j_cm2\":    \"float64\",\n",
    "            \"wmo_present_weather\":        \"float64\",\n",
    "        }\n",
    "\n",
    "    def read_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"Lecture brute du CSV (séparateur ';').\"\"\"\n",
    "        try:\n",
    "            return pd.read_csv(self.file_path, sep=\";\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Erreur API météo : {e}\")\n",
    "\n",
    "    def _select_rename(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Garde uniquement les colonnes connues puis les renomme (sans boucles).\"\"\"\n",
    "        cols_src = df.columns.intersection(self.WEATHER_COL_MAP.keys())\n",
    "        return df.loc[:, cols_src].rename(columns=self.WEATHER_COL_MAP)\n",
    "\n",
    "    def read_standardized(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Pipeline vectorisé :\n",
    "        - select/rename\n",
    "        - parse timestamp (AAAAMMJJHH)\n",
    "        - coalesce pression (PSTAT prioritaire sur PMER)\n",
    "        - cast global selon schéma\n",
    "        - ordre de colonnes propre\n",
    "        \"\"\"\n",
    "        df_raw = self.read_dataframe()\n",
    "        df = self._select_rename(df_raw)\n",
    "\n",
    "        # Parse timestamp (format AAAAMMJJHH)\n",
    "        df = df.assign(\n",
    "            timestamp=pd.to_datetime(\n",
    "                df[\"timestamp\"].astype(\"string\"),\n",
    "                format=\"%Y%m%d%H\",\n",
    "                errors=\"coerce\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Coalesce pression (priorité station -> mer) si colonnes présentes\n",
    "        # (si absentes, bfill s'applique sur colonnes manquantes sans boucle)\n",
    "        pressure_sources = df.filter(items=[\"pressure_hpa_station\", \"pressure_hpa_sea\"])\n",
    "        if not pressure_sources.empty:\n",
    "            df[\"pressure_hpa\"] = pressure_sources.bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "        # Ordre + cast en une seule passe (les colonnes manquantes seront ajoutées vides)\n",
    "        df = (\n",
    "            df\n",
    "            .reindex(columns=self.WEATHER_DTYPES.keys())  # ordre final\n",
    "            .astype(self.WEATHER_DTYPES, errors=\"ignore\")  # cast \"df.cast(schema)\" version pandas\n",
    "        )\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4119355",
   "metadata": {},
   "source": [
    "# Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427cb21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données Vélos :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capacity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "available_mechanical",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "available_electrical",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_geo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "operative",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "5188a36f-f2d0-4251-9b44-6a0bee0d0c73",
       "rows": [
        [
         "0",
         "2020-11-26T12:59Z",
         "35",
         "4",
         "5",
         "Benjamin Godard - Victor Hugo",
         "48.86598,2.27572",
         "True"
        ],
        [
         "1",
         "2020-11-26T12:59Z",
         "55",
         "23",
         "4",
         "André Mazet - Saint-André des Arts",
         "48.85376,2.33910",
         "True"
        ],
        [
         "2",
         "2020-11-26T12:59Z",
         "20",
         "0",
         "0",
         "Charonne - Robert et Sonia Delauney",
         "48.85591,2.39257",
         "True"
        ],
        [
         "3",
         "2020-11-26T12:59Z",
         "21",
         "0",
         "1",
         "Toudouze - Clauzel",
         "48.87930,2.33736",
         "True"
        ],
        [
         "4",
         "2020-11-26T12:59Z",
         "30",
         "3",
         "1",
         "Mairie du 12ème",
         "48.84086,2.38755",
         "True"
        ],
        [
         "5",
         "2020-11-26T12:59Z",
         "46",
         "18",
         "10",
         "Harpe - Saint-Germain",
         "48.85152,2.34367",
         "True"
        ],
        [
         "6",
         "2020-11-26T12:59Z",
         "60",
         "5",
         "2",
         "Jourdan - Stade Charléty",
         "48.81943,2.34334",
         "True"
        ],
        [
         "7",
         "2020-11-26T12:59Z",
         "40",
         "15",
         "1",
         "Jouffroy d'Abbans - Wagram",
         "48.88197,2.30113",
         "True"
        ],
        [
         "8",
         "2020-11-26T12:59Z",
         "39",
         "12",
         "2",
         "Guersant - Gouvion-Saint-Cyr",
         "48.88288,2.28767",
         "True"
        ],
        [
         "9",
         "2020-11-26T12:59Z",
         "60",
         "2",
         "2",
         "Alibert - Jemmapes",
         "48.87104,2.36610",
         "True"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>capacity</th>\n",
       "      <th>available_mechanical</th>\n",
       "      <th>available_electrical</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_geo</th>\n",
       "      <th>operative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Benjamin Godard - Victor Hugo</td>\n",
       "      <td>48.86598,2.27572</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>André Mazet - Saint-André des Arts</td>\n",
       "      <td>48.85376,2.33910</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Charonne - Robert et Sonia Delauney</td>\n",
       "      <td>48.85591,2.39257</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toudouze - Clauzel</td>\n",
       "      <td>48.87930,2.33736</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mairie du 12ème</td>\n",
       "      <td>48.84086,2.38755</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>Harpe - Saint-Germain</td>\n",
       "      <td>48.85152,2.34367</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Jourdan - Stade Charléty</td>\n",
       "      <td>48.81943,2.34334</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Jouffroy d'Abbans - Wagram</td>\n",
       "      <td>48.88197,2.30113</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>Guersant - Gouvion-Saint-Cyr</td>\n",
       "      <td>48.88288,2.28767</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Alibert - Jemmapes</td>\n",
       "      <td>48.87104,2.36610</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time  capacity  available_mechanical  available_electrical  \\\n",
       "0  2020-11-26T12:59Z        35                     4                     5   \n",
       "1  2020-11-26T12:59Z        55                    23                     4   \n",
       "2  2020-11-26T12:59Z        20                     0                     0   \n",
       "3  2020-11-26T12:59Z        21                     0                     1   \n",
       "4  2020-11-26T12:59Z        30                     3                     1   \n",
       "5  2020-11-26T12:59Z        46                    18                    10   \n",
       "6  2020-11-26T12:59Z        60                     5                     2   \n",
       "7  2020-11-26T12:59Z        40                    15                     1   \n",
       "8  2020-11-26T12:59Z        39                    12                     2   \n",
       "9  2020-11-26T12:59Z        60                     2                     2   \n",
       "\n",
       "                          station_name       station_geo  operative  \n",
       "0        Benjamin Godard - Victor Hugo  48.86598,2.27572       True  \n",
       "1   André Mazet - Saint-André des Arts  48.85376,2.33910       True  \n",
       "2  Charonne - Robert et Sonia Delauney  48.85591,2.39257       True  \n",
       "3                   Toudouze - Clauzel  48.87930,2.33736       True  \n",
       "4                      Mairie du 12ème  48.84086,2.38755       True  \n",
       "5                Harpe - Saint-Germain  48.85152,2.34367       True  \n",
       "6             Jourdan - Stade Charléty  48.81943,2.34334       True  \n",
       "7           Jouffroy d'Abbans - Wagram  48.88197,2.30113       True  \n",
       "8         Guersant - Gouvion-Saint-Cyr  48.88288,2.28767       True  \n",
       "9                   Alibert - Jemmapes  48.87104,2.36610       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données vacances :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "holiday_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_date",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "end_date",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "zones",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "description",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "a63e8930-f11e-4aa8-94a1-d2d3750e0ed2",
       "rows": [
        [
         "0",
         "2030-01-01 00:00:00",
         "1er janvier",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "2030-04-22 00:00:00",
         "Lundi de Pâques",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "2030-05-01 00:00:00",
         "1er mai",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "2030-05-08 00:00:00",
         "8 mai",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "2030-05-30 00:00:00",
         "Ascension",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "2030-06-10 00:00:00",
         "Lundi de Pentecôte",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "2030-07-14 00:00:00",
         "14 juillet",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "2030-08-15 00:00:00",
         "Assomption",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "8",
         "2030-11-01 00:00:00",
         "Toussaint",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "2030-11-11 00:00:00",
         "11 novembre",
         "holiday",
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>holiday_name</th>\n",
       "      <th>type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>zones</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030-01-01</td>\n",
       "      <td>1er janvier</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030-04-22</td>\n",
       "      <td>Lundi de Pâques</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2030-05-01</td>\n",
       "      <td>1er mai</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2030-05-08</td>\n",
       "      <td>8 mai</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030-05-30</td>\n",
       "      <td>Ascension</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2030-06-10</td>\n",
       "      <td>Lundi de Pentecôte</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2030-07-14</td>\n",
       "      <td>14 juillet</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2030-08-15</td>\n",
       "      <td>Assomption</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2030-11-01</td>\n",
       "      <td>Toussaint</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2030-11-11</td>\n",
       "      <td>11 novembre</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        holiday_name     type start_date end_date zones  \\\n",
       "0 2030-01-01         1er janvier  holiday        NaT      NaT   NaN   \n",
       "1 2030-04-22     Lundi de Pâques  holiday        NaT      NaT   NaN   \n",
       "2 2030-05-01             1er mai  holiday        NaT      NaT   NaN   \n",
       "3 2030-05-08               8 mai  holiday        NaT      NaT   NaN   \n",
       "4 2030-05-30           Ascension  holiday        NaT      NaT   NaN   \n",
       "5 2030-06-10  Lundi de Pentecôte  holiday        NaT      NaT   NaN   \n",
       "6 2030-07-14          14 juillet  holiday        NaT      NaT   NaN   \n",
       "7 2030-08-15          Assomption  holiday        NaT      NaT   NaN   \n",
       "8 2030-11-01           Toussaint  holiday        NaT      NaT   NaN   \n",
       "9 2030-11-11         11 novembre  holiday        NaT      NaT   NaN   \n",
       "\n",
       "  description  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données météo :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_id",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "station_name",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "lat_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alt_m",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "precip_mm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precip_dur_min",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "temp_c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dewpoint_c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "humidity_rel_pct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_speed_10m_ms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_dir_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_gust_10m_ms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pressure_hpa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cloud_oktas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "insolation_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "global_radiation_j_cm2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wmo_present_weather",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "81ff0cfd-4903-435a-8415-183c314e74d7",
       "rows": [
        [
         "0",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 00:00:00",
         "0.0",
         "0",
         "0.7",
         "-3.3",
         "74.0",
         "8.9",
         "140.0",
         "14.0",
         "1013.8",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 01:00:00",
         "0.0",
         "0",
         "0.9",
         "-3.3",
         "74.0",
         "9.7",
         "150.0",
         "14.7",
         "1013.1",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 02:00:00",
         "0.0",
         "0",
         "0.7",
         "-2.2",
         "81.0",
         "10.2",
         "140.0",
         "14.3",
         "1012.6",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 03:00:00",
         "0.0",
         "20",
         "0.8",
         "-2.2",
         "81.0",
         "11.5",
         "130.0",
         "16.5",
         "1011.0",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 04:00:00",
         "0.0",
         "0",
         "0.9",
         "-2.0",
         "82.0",
         "12.9",
         "120.0",
         "18.0",
         "1008.7",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 05:00:00",
         "0.0",
         "10",
         "0.5",
         "-1.2",
         "89.0",
         "13.7",
         "120.0",
         "20.2",
         "1006.4",
         "8.0",
         "0.0",
         "0.0",
         "70.0"
        ],
        [
         "6",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 06:00:00",
         "0.0",
         "60",
         "0.6",
         "-0.5",
         "92.0",
         "14.0",
         "120.0",
         "22.3",
         "1005.0",
         "8.0",
         "0.0",
         "0.0",
         "68.0"
        ],
        [
         "7",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 07:00:00",
         "0.4",
         "60",
         "0.6",
         "0.0",
         "96.0",
         "14.6",
         "120.0",
         "22.1",
         "1003.6",
         "8.0",
         "0.0",
         "0.0",
         "68.0"
        ],
        [
         "8",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 08:00:00",
         "1.2",
         "60",
         "0.8",
         "0.2",
         "96.0",
         "15.0",
         "120.0",
         "23.6",
         "1001.7",
         "8.0",
         "0.0",
         "0.0",
         "68.0"
        ],
        [
         "9",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 09:00:00",
         "5.1",
         "60",
         "0.9",
         "0.4",
         "97.0",
         "14.1",
         "110.0",
         "21.2",
         "1001.2",
         "8.0",
         "0.0",
         "0.0",
         "68.0"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>lat_deg</th>\n",
       "      <th>lon_deg</th>\n",
       "      <th>alt_m</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>precip_mm</th>\n",
       "      <th>precip_dur_min</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>dewpoint_c</th>\n",
       "      <th>humidity_rel_pct</th>\n",
       "      <th>wind_speed_10m_ms</th>\n",
       "      <th>wind_dir_deg</th>\n",
       "      <th>wind_gust_10m_ms</th>\n",
       "      <th>pressure_hpa</th>\n",
       "      <th>cloud_oktas</th>\n",
       "      <th>insolation_min</th>\n",
       "      <th>global_radiation_j_cm2</th>\n",
       "      <th>wmo_present_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>140.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1013.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>150.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>120.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>89.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>120.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>1006.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 07:00:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>120.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>1003.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>1001.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 09:00:00</td>\n",
       "      <td>5.1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>1001.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id station_name    lat_deg    lon_deg  alt_m           timestamp  \\\n",
       "0   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 00:00:00   \n",
       "1   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 01:00:00   \n",
       "2   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 02:00:00   \n",
       "3   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 03:00:00   \n",
       "4   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 04:00:00   \n",
       "5   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 05:00:00   \n",
       "6   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 06:00:00   \n",
       "7   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 07:00:00   \n",
       "8   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 08:00:00   \n",
       "9   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 09:00:00   \n",
       "\n",
       "   precip_mm  precip_dur_min  temp_c  dewpoint_c  humidity_rel_pct  \\\n",
       "0        0.0               0     0.7        -3.3              74.0   \n",
       "1        0.0               0     0.9        -3.3              74.0   \n",
       "2        0.0               0     0.7        -2.2              81.0   \n",
       "3        0.0              20     0.8        -2.2              81.0   \n",
       "4        0.0               0     0.9        -2.0              82.0   \n",
       "5        0.0              10     0.5        -1.2              89.0   \n",
       "6        0.0              60     0.6        -0.5              92.0   \n",
       "7        0.4              60     0.6         0.0              96.0   \n",
       "8        1.2              60     0.8         0.2              96.0   \n",
       "9        5.1              60     0.9         0.4              97.0   \n",
       "\n",
       "   wind_speed_10m_ms  wind_dir_deg  wind_gust_10m_ms  pressure_hpa  \\\n",
       "0                8.9         140.0              14.0        1013.8   \n",
       "1                9.7         150.0              14.7        1013.1   \n",
       "2               10.2         140.0              14.3        1012.6   \n",
       "3               11.5         130.0              16.5        1011.0   \n",
       "4               12.9         120.0              18.0        1008.7   \n",
       "5               13.7         120.0              20.2        1006.4   \n",
       "6               14.0         120.0              22.3        1005.0   \n",
       "7               14.6         120.0              22.1        1003.6   \n",
       "8               15.0         120.0              23.6        1001.7   \n",
       "9               14.1         110.0              21.2        1001.2   \n",
       "\n",
       "   cloud_oktas  insolation_min  global_radiation_j_cm2  wmo_present_weather  \n",
       "0          8.0             0.0                     0.0                  0.0  \n",
       "1          8.0             0.0                     0.0                  0.0  \n",
       "2          8.0             0.0                     0.0                  0.0  \n",
       "3          8.0             0.0                     0.0                  0.0  \n",
       "4          8.0             0.0                     0.0                  0.0  \n",
       "5          8.0             0.0                     0.0                 70.0  \n",
       "6          8.0             0.0                     0.0                 68.0  \n",
       "7          8.0             0.0                     0.0                 68.0  \n",
       "8          8.0             0.0                     0.0                 68.0  \n",
       "9          8.0             0.0                     0.0                 68.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "velib_historical_dataframe = VelibCsvReader().read_dataframe()\n",
    "print(\"Données Vélos :\")\n",
    "display(velib_historical_dataframe.head(10))\n",
    "\n",
    "holidays_instance = HolidaysAPI()\n",
    "public_holidays_dataframe = holidays_instance.fetch_public_holidays()\n",
    "vacations_dataframe = holidays_instance.fetch_school_vacations()\n",
    "public_holidays_dataframe[\"type\"] = \"holiday\"\n",
    "vacations_dataframe[\"type\"] = \"vacation\"\n",
    "calendar_dataframe = pd.concat([public_holidays_dataframe, vacations_dataframe], ignore_index=True)\n",
    "print(\"Données vacances :\")\n",
    "display(calendar_dataframe.head(10))\n",
    "\n",
    "weather_dataframe = WeatherCsvReader().read_standardized()\n",
    "print(\"Données météo :\")\n",
    "display(weather_dataframe.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f7988",
   "metadata": {},
   "source": [
    "# Modélisation des données\n",
    "## Fonctions de modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c1bf5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Préparation des données...\n",
      "⚙️ Construction des features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29840\\2493534093.py:70: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"fill_rate\"] = (df[\"available_total\"] / df[\"capacity\"].replace(0, pd.NA)).fillna(0).clip(0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📏 Seuils appliqués: target_empty >= 0.83 | target_full >= 0.17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class FeatureBuilder:\n",
    "    def __init__(self, velib, weather, calendar):\n",
    "        self.velib = velib\n",
    "        self.weather = weather\n",
    "        self.calendar = calendar\n",
    "\n",
    "    def _preprocess(self, velib, weather, calendar):\n",
    "        \"\"\"Prépare et fusionne les datasets (fusion horaire simple)\"\"\"\n",
    "        print(\"🧹 Préparation des données...\")\n",
    "\n",
    "        # Nettoyage des dates (UTC)\n",
    "        weather[\"timestamp\"] = pd.to_datetime(weather[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "        velib[\"time\"] = pd.to_datetime(velib[\"time\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "        # Clé horaire\n",
    "        weather[\"ts_hour\"] = weather[\"timestamp\"].dt.floor(\"h\")\n",
    "        velib[\"ts_hour\"] = velib[\"time\"].dt.floor(\"h\")\n",
    "\n",
    "        # ===== Flags météo très simples (0/1) =====\n",
    "        precip = pd.to_numeric(weather.get(\"precip_mm\", 0), errors=\"coerce\").fillna(0.0)\n",
    "        precip_dur = pd.to_numeric(weather.get(\"precip_dur_min\", 0), errors=\"coerce\").fillna(0.0)\n",
    "        ws = pd.to_numeric(weather.get(\"wind_speed_10m_ms\", 0), errors=\"coerce\").fillna(0.0)\n",
    "        wg = pd.to_numeric(weather.get(\"wind_gust_10m_ms\", 0), errors=\"coerce\").fillna(0.0)\n",
    "        cloud_oktas = pd.to_numeric(weather.get(\"cloud_oktas\", np.nan), errors=\"coerce\")\n",
    "\n",
    "        # Règles binaires\n",
    "        weather[\"pluie\"]  = ((precip >= 0.1) | (precip_dur >= 5)).astype(int)\n",
    "        weather[\"vent\"]   = ((ws >= 8.0) | (wg >= 10.8)).astype(int)\n",
    "        weather[\"soleil\"] = cloud_oktas.le(2).fillna(False).astype(int)\n",
    "        weather[\"nuage\"]  = cloud_oktas.ge(6).fillna(False).astype(int)\n",
    "\n",
    "        # 1 ligne par heure\n",
    "        weather_flags = (\n",
    "            weather.sort_values(\"timestamp\")\n",
    "                   .drop_duplicates(subset=[\"ts_hour\"], keep=\"last\")\n",
    "                   [[\"ts_hour\", \"pluie\", \"vent\", \"soleil\", \"nuage\"]]\n",
    "                   .copy()\n",
    "        )\n",
    "        weather_flags[[\"pluie\", \"vent\", \"soleil\", \"nuage\"]] = weather_flags[[\"pluie\", \"vent\", \"soleil\", \"nuage\"]].fillna(0).astype(int)\n",
    "\n",
    "        # Fusion météo ↔ Vélib\n",
    "        df = velib.merge(weather_flags, on=\"ts_hour\", how=\"left\")\n",
    "        for c in [\"pluie\", \"vent\", \"soleil\", \"nuage\"]:\n",
    "            if c not in df.columns:\n",
    "                df[c] = 0\n",
    "        df[[\"pluie\", \"vent\", \"soleil\", \"nuage\"]] = df[[\"pluie\", \"vent\", \"soleil\", \"nuage\"]].fillna(0).astype(int)\n",
    "\n",
    "        # Ajout calendrier\n",
    "        df[\"date\"] = df[\"time\"].dt.tz_convert(\"Europe/Paris\").dt.date\n",
    "        cal = calendar.copy()\n",
    "        cal[\"date\"] = pd.to_datetime(cal[\"start_date\"]).dt.date\n",
    "        cal[\"holiday_flag\"] = 1\n",
    "        df = df.merge(cal[[\"date\", \"holiday_flag\"]].drop_duplicates(), on=\"date\", how=\"left\")\n",
    "        df[\"holiday_flag\"] = df[\"holiday_flag\"].fillna(0).astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _feature_engineering(self, df):\n",
    "        \"\"\"Crée des variables dérivées utiles pour la prédiction\"\"\"\n",
    "        print(\"⚙️ Construction des features...\")\n",
    "\n",
    "        # TOTAL vélos dispo & bornes libres\n",
    "        df[\"available_total\"] = df[\"available_mechanical\"].fillna(0) + df[\"available_electrical\"].fillna(0)\n",
    "        df[\"docks_available\"] = df[\"capacity\"].fillna(0) - df[\"available_total\"]\n",
    "\n",
    "        # Taux d'occupation\n",
    "        df[\"fill_rate\"] = (df[\"available_total\"] / df[\"capacity\"].replace(0, pd.NA)).fillna(0).clip(0, 1)\n",
    "\n",
    "        # ✅ Calcul des ratios sûrs\n",
    "        ratio_empty = (df[\"docks_available\"] / df[\"capacity\"].replace(0, np.nan)).replace([np.inf, -np.inf], np.nan).fillna(0).clip(0, 1)\n",
    "        ratio_full = (df[\"available_total\"] / df[\"capacity\"].replace(0, np.nan)).replace([np.inf, -np.inf], np.nan).fillna(0).clip(0, 1)\n",
    "\n",
    "        # ✅ Définition automatique des seuils (adaptés à ta distribution)\n",
    "        empty_threshold = ratio_empty.quantile(0.70)  # stations avec beaucoup de place\n",
    "        full_threshold  = ratio_full.quantile(0.30)   # stations avec assez de vélos\n",
    "\n",
    "        print(f\"📏 Seuils appliqués: target_empty >= {empty_threshold:.2f} | target_full >= {full_threshold:.2f}\")\n",
    "\n",
    "        # ✅ Cibles binaires équilibrées\n",
    "        df[\"target_empty\"] = (ratio_empty >= empty_threshold).astype(int)\n",
    "        df[\"target_full\"]  = (ratio_full >= full_threshold).astype(int)\n",
    "\n",
    "        # Heures / jours\n",
    "        df = df.sort_values([\"station_name\", \"time\"])\n",
    "        df[\"hour\"] = df[\"time\"].dt.hour\n",
    "        df[\"day_of_week\"] = df[\"time\"].dt.day_name()\n",
    "\n",
    "        # Moyenne glissante (3h) par station\n",
    "        df[\"rolling_fill_rate\"] = (\n",
    "            df.groupby(\"station_name\")[\"fill_rate\"].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "        # Week-end\n",
    "        df[\"is_weekend\"] = df[\"day_of_week\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Exécution complète du pipeline de feature engineering\"\"\"\n",
    "        merged = self._preprocess(self.velib, self.weather, self.calendar)\n",
    "        if merged is None:\n",
    "            raise RuntimeError(\"[FeatureBuilder.run] _preprocess a renvoyé None (attendu: DataFrame).\")\n",
    "        features = self._feature_engineering(merged)\n",
    "        return features\n",
    "\n",
    "\n",
    "# 🧪 Exemple d'exécution\n",
    "feature_dataframe = FeatureBuilder(\n",
    "    velib_historical_dataframe,\n",
    "    weather_dataframe,\n",
    "    calendar_dataframe\n",
    ").run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56712983",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d6a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "43ac4025-d334-4c0f-90eb-7556c6a53574",
       "rows": [
        [
         "519",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "1916",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "3313",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "4710",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "6107",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "7504",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "8901",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "10298",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "11695",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "13092",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "14489",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "15886",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "17283",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "18680",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "20077",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "21474",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "22871",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "24268",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "25665",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "27062",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "28459",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "29856",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "31253",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "32650",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "34047",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "35444",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "36841",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "38238",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "39635",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "41032",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "42429",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "43826",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "45223",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "46620",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "48017",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "49414",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "50811",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "52208",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "53605",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "55002",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "56399",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "57796",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "59193",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "60590",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "61987",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "63384",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "64781",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "66178",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "67575",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "68972",
         " Jean Bleuzen - Square du 11 Novembre"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10986730
       }
      },
      "text/plain": [
       "519          Jean Bleuzen - Square du 11 Novembre\n",
       "1916         Jean Bleuzen - Square du 11 Novembre\n",
       "3313         Jean Bleuzen - Square du 11 Novembre\n",
       "4710         Jean Bleuzen - Square du 11 Novembre\n",
       "6107         Jean Bleuzen - Square du 11 Novembre\n",
       "                            ...                  \n",
       "10980677                          Île de la Jatte\n",
       "10982075                          Île de la Jatte\n",
       "10983473                          Île de la Jatte\n",
       "10984872                          Île de la Jatte\n",
       "10986271                          Île de la Jatte\n",
       "Name: station_name, Length: 10986730, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultat = feature_dataframe[\"station_name\"].groupby(\"station_name\").count()\n",
    "\n",
    "display(resultat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import joblib\n",
    "\n",
    "\n",
    "class VelibSimpleModel:\n",
    "    \"\"\"\n",
    "    Modèle simple et lisible pour prédire si une station sera vide/pleine.\n",
    "\n",
    "    Principes :\n",
    "    - Utilise uniquement les colonnes déjà présentes dans votre DataFrame d'exemple\n",
    "      (pas de météo, pas de mapping).\n",
    "    - Encodage temporel cyclique (à partir de 'time').\n",
    "    - Imputation légère + standardisation pour les numériques, OHE pour station_id.\n",
    "    - API courte: fit / predict_proba / predict_label / save / load\n",
    "    - Paramètres regroupés en dict (to_config / from_config).\n",
    "    \"\"\"\n",
    "\n",
    "    # Colonnes de base attendues (selon votre DataFrame d'entrée)\n",
    "    BASE_NUM_SCALED: List[str] = [\n",
    "        # features temporelles\n",
    "        \"hour_ssin\", \"hour_ccos\", \"dow_sin\", \"dow_cos\", \"month\",\n",
    "    ]\n",
    "    BASE_BIN_PASSTHROUGH: List[str] = [\n",
    "        \"holiday_flag\", \"is_weekend\", \"operative\",\n",
    "        \"pluie\", \"vent\", \"soleil\", \"nuage\",\n",
    "    ]\n",
    "    BASE_CATEG: List[str] = [\"station_name\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_col: str = \"target_empty\",        # ou \"target_full\"\n",
    "        model_type: str = \"gb\",                  # \"gb\" ou \"logit\"\n",
    "        timezone: str = \"Europe/Paris\",\n",
    "        random_state: int = 42,\n",
    "        test_size: float = 0.2,\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "        print(\"[__init__] → Début initialisation du modèle\")\n",
    "        self.target_col = target_col\n",
    "        self.model_type = model_type\n",
    "        self.timezone = timezone\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Objets entraînés\n",
    "        self.feature_list_: List[str] = []\n",
    "        self.preprocessor_: Optional[ColumnTransformer] = None\n",
    "        self.pipeline_: Optional[Pipeline] = None\n",
    "        print(\"[__init__] ✓ Fin initialisation du modèle\")\n",
    "\n",
    "    # ------------- Helpers ---------------\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_columns(df: pd.DataFrame, cols: List[str]) -> None:\n",
    "        print(\"[_ensure_columns] → Vérification des colonnes requises...\")\n",
    "        missing = [c for c in cols if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Colonnes manquantes: {missing}\")\n",
    "        print(\"[_ensure_columns] ✓ Toutes les colonnes sont présentes.\")\n",
    "\n",
    "    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Ajoute hour/dow/month + encodage cyclique à partir de la colonne 'time'.\n",
    "        On ne dépend pas des colonnes 'hour'/'day_of_week' existantes pour garder la logique simple et robuste.\n",
    "        \"\"\"\n",
    "        print(\"[_add_time_features] → Début génération des features temporelles...\")\n",
    "        if \"time\" not in df.columns:\n",
    "            raise ValueError(\"La colonne 'time' est requise.\")\n",
    "        ts = pd.to_datetime(df[\"time\"], utc=True).dt.tz_convert(self.timezone)\n",
    "\n",
    "        out = df.copy()\n",
    "        out[\"hour\"] = ts.dt.hour\n",
    "        out[\"dow\"] = ts.dt.weekday     # 0 = lundi\n",
    "        out[\"month\"] = ts.dt.month\n",
    "\n",
    "        out[\"hour_ssin\"] = np.sin(2 * np.pi * out[\"hour\"] / 24)\n",
    "        out[\"hour_ccos\"] = np.cos(2 * np.pi * out[\"hour\"] / 24)\n",
    "        out[\"dow_sin\"]   = np.sin(2 * np.pi * out[\"dow\"] / 7)\n",
    "        out[\"dow_cos\"]   = np.cos(2 * np.pi * out[\"dow\"] / 7)\n",
    "        print(\"[_add_time_features] ✓ Features temporelles ajoutées.\")\n",
    "        return out\n",
    "\n",
    "    def _build_preprocessor(self) -> None:\n",
    "        \"\"\"\n",
    "        Préprocesseur:\n",
    "        - Numériques (imputation médiane + standardisation)\n",
    "        - Binaires (imputation la plus fréquente, pas de scaling)\n",
    "        - Catégorielles (OHE handle_unknown='ignore')\n",
    "        \"\"\"\n",
    "        print(\"[_build_preprocessor] → Construction du préprocesseur...\")\n",
    "        # Gestion valeurs manquantes + standardisation\n",
    "        num_pipe = Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\", StandardScaler()),\n",
    "        ])\n",
    "        # Gestion valeurs manquantes (pas scaler pour garder 0/1 lisible)\n",
    "        bin_pipe = Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ])\n",
    "        # Transforme variables catégorielles en binaire\n",
    "        cat_pipe = Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")),\n",
    "            (\"ohe\", OneHotEncoder(\n",
    "                handle_unknown=\"ignore\",\n",
    "                dtype=np.float32,\n",
    "                sparse_output=True,\n",
    "            )),\n",
    "        ])\n",
    "\n",
    "        # Liste des features finales\n",
    "        self.feature_list_ = (\n",
    "            self.BASE_NUM_SCALED\n",
    "            + self.BASE_BIN_PASSTHROUGH\n",
    "            + self.BASE_CATEG\n",
    "        )\n",
    "\n",
    "        # Applique les 3 pipelines de transformation + drop autres colonnes\n",
    "        self.preprocessor_ = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", num_pipe, self.BASE_NUM_SCALED),\n",
    "                (\"bin\", bin_pipe, self.BASE_BIN_PASSTHROUGH),\n",
    "                (\"cat\", cat_pipe, self.BASE_CATEG),\n",
    "            ],\n",
    "            remainder=\"drop\",\n",
    "            sparse_threshold=1.0,\n",
    "        )\n",
    "        print(\"[_build_preprocessor] ✓ Préprocesseur construit.\")\n",
    "\n",
    "    def _prepare_features(\n",
    "        self, df: pd.DataFrame, with_target: bool\n",
    "    ) -> Tuple[pd.DataFrame, Optional[pd.Series]]:\n",
    "        \"\"\"\n",
    "        - Ajoute les features temporelles\n",
    "        - Vérifie la présence des colonnes attendues\n",
    "        - Renvoie X (et y si with_target)\n",
    "        \"\"\"\n",
    "        print(\"[_prepare_features] → Préparation des features...\")\n",
    "        # Ajoute les features temporelles\n",
    "        df2 = self._add_time_features(df)\n",
    "\n",
    "        # Construire le préprocesseur si pas encore fait\n",
    "        if self.preprocessor_ is None:\n",
    "            self._build_preprocessor()\n",
    "\n",
    "        # Vérifier les colonnes d'entrée attendues\n",
    "        needed = (\n",
    "            set(self.BASE_NUM_SCALED + self.BASE_BIN_PASSTHROUGH + self.BASE_CATEG)\n",
    "            - {\"hour_ssin\", \"hour_ccos\", \"dow_sin\", \"dow_cos\", \"month\"}  # créées ici\n",
    "        )\n",
    "        self._ensure_columns(df2, sorted(needed))\n",
    "\n",
    "        X = df2[self.feature_list_] # Liste de colonne créée dans _build_preprocessor()\n",
    "\n",
    "        y = None\n",
    "        if with_target: # Vérification de la présence de la colonne cible (à prédire)\n",
    "            if self.target_col not in df2.columns:\n",
    "                raise ValueError(f\"Colonne cible manquante: '{self.target_col}'\")\n",
    "            y = df2[self.target_col].astype(int)\n",
    "\n",
    "        # Renvoi les colonnes de paramètre ainsi que la colonne cible \n",
    "        print(\"[_prepare_features] ✓ Features préparées.\")\n",
    "        return X, y\n",
    "\n",
    "    # ------------- API publique ---------------\n",
    "\n",
    "    def fit(self, df: pd.DataFrame) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Entraîne le modèle choisi et renvoie des métriques simples (AUC).\n",
    "        \"\"\"\n",
    "        print(\"[fit] → Début entraînement du modèle...\")\n",
    "        \n",
    "        self._build_preprocessor()# (ré)initialise un préprocesseur propre\n",
    "        X, y = self._prepare_features(df, with_target=True) # Préparation des features\n",
    "\n",
    "        # Choix du classifieur\n",
    "        if self.model_type == \"logit\":\n",
    "            classifier = LogisticRegression(max_iter=300, solver=\"saga\", verbose=1, random_state=self.random_state)\n",
    "        else:\n",
    "            classifier = GradientBoostingClassifier(random_state=self.random_state, verbose=1)\n",
    "\n",
    "        # Assemblage préprocesseur + classifieur\n",
    "        self.pipeline_ = Pipeline(steps=[(\"preprocessor\", self.preprocessor_), (\"classifier\", classifier)])\n",
    "\n",
    "        X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "            X, y,\n",
    "            test_size=self.test_size,\n",
    "            stratify=y,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "\n",
    "        print(\"[fit] → Entraînement en cours...\")\n",
    "        self.pipeline_.fit(X_tr, y_tr)\n",
    "\n",
    "        print(\"[fit] ✓ Entraînement terminé. Évaluation en cours...\")\n",
    "\n",
    "        proba = self.pipeline_.predict_proba(X_va)[:, 1]\n",
    "        y_pred = (proba >= 0.5).astype(int)  # seuil simple\n",
    "\n",
    "        acc = accuracy_score(y_va, y_pred)\n",
    "        f1  = f1_score(y_va, y_pred)\n",
    "\n",
    "        metrics = {\n",
    "            \"val_accuracy\": float(acc),\n",
    "            \"val_f1\": float(f1),\n",
    "            \"n_samples_train\": int(len(X_tr)),\n",
    "            \"n_samples_val\": int(len(X_va)),\n",
    "        }\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"[{self.target_col}] {self.model_type.upper()}  \"\n",
    "                f\"ACC={metrics['val_accuracy']:.3f}  F1={metrics['val_f1']:.3f}  \"\n",
    "                f\"(train={metrics['n_samples_train']}, val={metrics['n_samples_val']})\")\n",
    "\n",
    "\n",
    "        print(\"[fit] ✓ Fin de l'entraînement et des métriques.\")\n",
    "        return metrics\n",
    "\n",
    "    def predict_proba(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Probabilité d'être positif (ex: vide si target_empty).\"\"\"\n",
    "        print(\"[predict_proba] → Début prédiction des probabilités...\")\n",
    "        check_is_fitted(self.pipeline_, \"named_steps\")\n",
    "        # NE PAS reconstruire le préprocesseur ici\n",
    "        X, _ = self._prepare_features(df, with_target=False)\n",
    "        print(\"[predict_proba] ✓ Fin prédiction des probabilités.\")\n",
    "        return self.pipeline_.predict_proba(X)[:, 1]\n",
    "\n",
    "    def predict_label(self, df: pd.DataFrame, threshold: float = 0.5) -> pd.Series:\n",
    "        \"\"\"Label binaire selon un seuil.\"\"\"\n",
    "        print(\"[predict_label] → Début prédiction des labels...\")\n",
    "        p = self.predict_proba(df)\n",
    "        print(\"[predict_label] ✓ Fin prédiction des labels.\")\n",
    "        return pd.Series((p >= threshold).astype(int), index=df.index, name=f\"{self.target_col}_pred\")\n",
    "\n",
    "    def save(self, path: str) -> None:\n",
    "        \"\"\"Sauvegarde le pipeline complet (prétraitement + modèle).\"\"\"\n",
    "        print(\"[save] → Sauvegarde du modèle...\")\n",
    "        check_is_fitted(self.pipeline_, \"named_steps\")\n",
    "        joblib.dump(self.pipeline_, path)\n",
    "        print(\"[save] ✓ Modèle sauvegardé.\")\n",
    "\n",
    "    def load(self, path: str) -> None:\n",
    "        \"\"\"Charge un pipeline entraîné (préprocesseur inclus).\"\"\"\n",
    "        print(\"[load] → Chargement du modèle...\")\n",
    "        self.pipeline_ = joblib.load(path)\n",
    "        # on récupère le préprocesseur et la liste de features du pipeline sauvegardé\n",
    "        if hasattr(self.pipeline_, \"named_steps\") and \"preprocessor\" in self.pipeline_.named_steps:\n",
    "            self.preprocessor_ = self.pipeline_.named_steps[\"preprocessor\"]\n",
    "        # La feature_list_ est utile seulement pour _prepare_features (ordre des colonnes en entrée)\n",
    "        # On la reconstruit à partir des attributs de classe pour rester déterministe :\n",
    "        self.feature_list_ = (\n",
    "            self.BASE_NUM_SCALED + self.BASE_BIN_PASSTHROUGH + self.BASE_CATEG\n",
    "        )\n",
    "        print(\"[load] ✓ Modèle chargé avec succès.\")\n",
    "\n",
    "    # --------- Config dict ---------\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, cfg: Dict) -> \"VelibSimpleModel\":\n",
    "        print(\"[from_config] → Création du modèle depuis un dictionnaire de config...\")\n",
    "        model = cls(**cfg)\n",
    "        print(\"[from_config] ✓ Modèle créé depuis la config.\")\n",
    "        return model\n",
    "\n",
    "    def to_config(self) -> Dict:\n",
    "        print(\"[to_config] → Export de la configuration du modèle...\")\n",
    "        cfg = {\n",
    "            \"target_col\": self.target_col,\n",
    "            \"model_type\": self.model_type,\n",
    "            \"timezone\": self.timezone,\n",
    "            \"random_state\": self.random_state,\n",
    "            \"test_size\": self.test_size,\n",
    "            \"verbose\": self.verbose,\n",
    "        }\n",
    "        print(\"[to_config] ✓ Configuration exportée.\")\n",
    "        return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb6b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[from_config] → Création du modèle depuis un dictionnaire de config...\n",
      "[__init__] → Début initialisation du modèle\n",
      "[__init__] ✓ Fin initialisation du modèle\n",
      "[from_config] ✓ Modèle créé depuis la config.\n",
      "[fit] → Début entraînement du modèle...\n",
      "[_build_preprocessor] → Construction du préprocesseur...\n",
      "[_build_preprocessor] ✓ Préprocesseur construit.\n",
      "[_prepare_features] → Préparation des features...\n",
      "[_add_time_features] → Début génération des features temporelles...\n",
      "[_add_time_features] ✓ Features temporelles ajoutées.\n",
      "[_ensure_columns] → Vérification des colonnes requises...\n",
      "[_ensure_columns] ✓ Toutes les colonnes sont présentes.\n",
      "[_prepare_features] ✓ Features préparées.\n",
      "[fit] → Entraînement en cours...\n",
      "convergence after 216 epochs took 1767 seconds\n",
      "[fit] ✓ Entraînement terminé. Évaluation en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 29.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target_full] LOGIT  ACC=0.777  F1=0.851  (train=8789384, val=2197346)\n",
      "[fit] ✓ Fin de l'entraînement et des métriques.\n",
      "📊 Résultats de l'entraînement :\n",
      "  - val_accuracy: 0.7769035918785663\n",
      "  - val_f1: 0.8512563802098346\n",
      "  - n_samples_train: 8789384\n",
      "  - n_samples_val: 2197346\n",
      "[save] → Sauvegarde du modèle...\n",
      "[save] ✓ Modèle sauvegardé.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Charger vos données\n",
    "df = feature_dataframe # pd.read_csv(\"velib_data.csv\")  # ou df = votre_dataframe déjà chargé\n",
    "\n",
    "# 2. Créer le modèle avec vos paramètres\n",
    "config = {\n",
    "    \"target_col\": \"target_full\",     # ou \"target_full\"\n",
    "    \"model_type\": \"logit\",               # \"gb\" ou \"logit\"\n",
    "    \"timezone\": \"Europe/Paris\",\n",
    "    \"random_state\": 42,\n",
    "    \"test_size\": 0.2,\n",
    "    \"verbose\": True\n",
    "}\n",
    "model = VelibSimpleModel.from_config(config)\n",
    "\n",
    "# 3. Lancer l'entraînement\n",
    "metrics = model.fit(feature_dataframe)\n",
    "\n",
    "# 4. Afficher les résultats\n",
    "print(\"📊 Résultats de l'entraînement :\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "# 5. (Optionnel) Sauvegarder le modèle\n",
    "model.save(\"target_full.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
