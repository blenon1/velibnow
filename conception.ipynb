{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83458767",
   "metadata": {},
   "source": [
    "# Fonctions d'obtention des donn√©es\n",
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbcb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from config import URL_HOLIDAYS, URL_SCHOOL, URL_METEO_HOURLY\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66032f0",
   "metadata": {},
   "source": [
    "## Class de lecture des donn√©es velib historiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd96b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VelibCsvReader:\n",
    "    def __init__(self):\n",
    "        self.file_path = \"./data/dataset/historique_stations.csv\"\n",
    "\n",
    "    def read_dataframe(self):\n",
    "        \"\"\"Combine status + info sur les stations\"\"\"\n",
    "        dataframe = pd.read_csv(\n",
    "            filepath_or_buffer=self.file_path,\n",
    "            sep=\",\"\n",
    "        )\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bfbf7c",
   "metadata": {},
   "source": [
    "## Class API pour donn√©es sur les vacances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01808ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HolidaysAPI:\n",
    "    \"\"\"\n",
    "    R√©cup√©ration des jours f√©ri√©s et des vacances scolaires fran√ßaises.\n",
    "    \"\"\"\n",
    "\n",
    "    def fetch_public_holidays(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            data = requests.get(URL_HOLIDAYS, timeout=10).json()\n",
    "            df = pd.DataFrame(list(data.items()), columns=[\"date\", \"holiday_name\"])\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Erreur API jours f√©ri√©s : {e}\")\n",
    "\n",
    "    def fetch_school_vacations(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            data = requests.get(URL_SCHOOL, timeout=10).json()\n",
    "            results = data.get(\"results\", [])\n",
    "            df = pd.DataFrame(results)\n",
    "            if not df.empty:\n",
    "                df = df[[\"start_date\", \"end_date\", \"zones\", \"description\"]]\n",
    "                df[\"start_date\"] = pd.to_datetime(df[\"start_date\"])\n",
    "                df[\"end_date\"] = pd.to_datetime(df[\"end_date\"])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Erreur API vacances scolaires : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee9993",
   "metadata": {},
   "source": [
    "## Class API pour les donn√©es m√©t√©o historiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7b4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "class WeatherCsvReader:\n",
    "    def __init__(self, file_path: str = \"./data/dataset/historical_meteo.csv\"):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "        # Mapping colonnes brutes -> colonnes standardis√©es\n",
    "        self.WEATHER_COL_MAP = {\n",
    "            \"AAAAMMJJHH\": \"timestamp\",\n",
    "            \"NUM_POSTE\":  \"station_id\",\n",
    "            \"NOM_USUEL\":  \"station_name\",\n",
    "            \"LAT\":        \"lat_deg\",\n",
    "            \"LON\":        \"lon_deg\",\n",
    "            \"ALTI\":       \"alt_m\",\n",
    "            \"RR1\":        \"precip_mm\",\n",
    "            \"DRR1\":       \"precip_dur_min\",\n",
    "            \"T\":          \"temp_c\",\n",
    "            \"TD\":         \"dewpoint_c\",\n",
    "            \"U\":          \"humidity_rel_pct\",\n",
    "            \"FF\":         \"wind_speed_10m_ms\",\n",
    "            \"DD\":         \"wind_dir_deg\",\n",
    "            \"FXI\":        \"wind_gust_10m_ms\",\n",
    "            \"PSTAT\":      \"pressure_hpa_station\",\n",
    "            \"PMER\":       \"pressure_hpa_sea\",\n",
    "\n",
    "            \"N\":          \"cloud_oktas\",\n",
    "            \"INS\":        \"insolation_min\",            # plan B si N absent\n",
    "            \"GLO\":        \"global_radiation_j_cm2\",    # plan B bis\n",
    "            \"WW\":         \"wmo_present_weather\",       # optionnel mais utile\n",
    "        }\n",
    "\n",
    "        # Sch√©ma final (cible) ‚Äî timestamp est pars√© √† part\n",
    "        self.WEATHER_DTYPES: Dict[str, str] = {\n",
    "            \"station_id\":          \"string\",\n",
    "            \"station_name\":        \"string\",\n",
    "            \"lat_deg\":             \"float64\",\n",
    "            \"lon_deg\":             \"float64\",\n",
    "            \"alt_m\":               \"Int64\",\n",
    "            \"timestamp\":           \"datetime64[ns]\",\n",
    "            \"precip_mm\":           \"float64\",\n",
    "            \"precip_dur_min\":      \"Int64\",\n",
    "            \"temp_c\":              \"float64\",\n",
    "            \"dewpoint_c\":          \"float64\",\n",
    "            \"humidity_rel_pct\":    \"float64\",\n",
    "            \"wind_speed_10m_ms\":   \"float64\",\n",
    "            \"wind_dir_deg\":        \"float64\",\n",
    "            \"wind_gust_10m_ms\":    \"float64\",\n",
    "            \"pressure_hpa\":        \"float64\",\n",
    "            \n",
    "            \"cloud_oktas\":   \"float64\",\n",
    "            \"insolation_min\":        \"float64\",\n",
    "            \"global_radiation_j_cm2\":    \"float64\",\n",
    "            \"wmo_present_weather\":        \"float64\",\n",
    "        }\n",
    "\n",
    "    def read_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"Lecture brute du CSV (s√©parateur ';').\"\"\"\n",
    "        try:\n",
    "            return pd.read_csv(self.file_path, sep=\";\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Erreur API m√©t√©o : {e}\")\n",
    "\n",
    "    def _select_rename(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Garde uniquement les colonnes connues puis les renomme (sans boucles).\"\"\"\n",
    "        cols_src = df.columns.intersection(self.WEATHER_COL_MAP.keys())\n",
    "        return df.loc[:, cols_src].rename(columns=self.WEATHER_COL_MAP)\n",
    "\n",
    "    def read_standardized(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Pipeline vectoris√© :\n",
    "        - select/rename\n",
    "        - parse timestamp (AAAAMMJJHH)\n",
    "        - coalesce pression (PSTAT prioritaire sur PMER)\n",
    "        - cast global selon sch√©ma\n",
    "        - ordre de colonnes propre\n",
    "        \"\"\"\n",
    "        df_raw = self.read_dataframe()\n",
    "        df = self._select_rename(df_raw)\n",
    "\n",
    "        # Parse timestamp (format AAAAMMJJHH)\n",
    "        df = df.assign(\n",
    "            timestamp=pd.to_datetime(\n",
    "                df[\"timestamp\"].astype(\"string\"),\n",
    "                format=\"%Y%m%d%H\",\n",
    "                errors=\"coerce\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Coalesce pression (priorit√© station -> mer) si colonnes pr√©sentes\n",
    "        # (si absentes, bfill s'applique sur colonnes manquantes sans boucle)\n",
    "        pressure_sources = df.filter(items=[\"pressure_hpa_station\", \"pressure_hpa_sea\"])\n",
    "        if not pressure_sources.empty:\n",
    "            df[\"pressure_hpa\"] = pressure_sources.bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "        # Ordre + cast en une seule passe (les colonnes manquantes seront ajout√©es vides)\n",
    "        df = (\n",
    "            df\n",
    "            .reindex(columns=self.WEATHER_DTYPES.keys())  # ordre final\n",
    "            .astype(self.WEATHER_DTYPES, errors=\"ignore\")  # cast \"df.cast(schema)\" version pandas\n",
    "        )\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4119355",
   "metadata": {},
   "source": [
    "# Exploration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427cb21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es V√©los :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capacity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "available_mechanical",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "available_electrical",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_geo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "operative",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "5188a36f-f2d0-4251-9b44-6a0bee0d0c73",
       "rows": [
        [
         "0",
         "2020-11-26T12:59Z",
         "35",
         "4",
         "5",
         "Benjamin Godard - Victor Hugo",
         "48.86598,2.27572",
         "True"
        ],
        [
         "1",
         "2020-11-26T12:59Z",
         "55",
         "23",
         "4",
         "Andr√© Mazet - Saint-Andr√© des Arts",
         "48.85376,2.33910",
         "True"
        ],
        [
         "2",
         "2020-11-26T12:59Z",
         "20",
         "0",
         "0",
         "Charonne - Robert et Sonia Delauney",
         "48.85591,2.39257",
         "True"
        ],
        [
         "3",
         "2020-11-26T12:59Z",
         "21",
         "0",
         "1",
         "Toudouze - Clauzel",
         "48.87930,2.33736",
         "True"
        ],
        [
         "4",
         "2020-11-26T12:59Z",
         "30",
         "3",
         "1",
         "Mairie du 12√®me",
         "48.84086,2.38755",
         "True"
        ],
        [
         "5",
         "2020-11-26T12:59Z",
         "46",
         "18",
         "10",
         "Harpe - Saint-Germain",
         "48.85152,2.34367",
         "True"
        ],
        [
         "6",
         "2020-11-26T12:59Z",
         "60",
         "5",
         "2",
         "Jourdan - Stade Charl√©ty",
         "48.81943,2.34334",
         "True"
        ],
        [
         "7",
         "2020-11-26T12:59Z",
         "40",
         "15",
         "1",
         "Jouffroy d'Abbans - Wagram",
         "48.88197,2.30113",
         "True"
        ],
        [
         "8",
         "2020-11-26T12:59Z",
         "39",
         "12",
         "2",
         "Guersant - Gouvion-Saint-Cyr",
         "48.88288,2.28767",
         "True"
        ],
        [
         "9",
         "2020-11-26T12:59Z",
         "60",
         "2",
         "2",
         "Alibert - Jemmapes",
         "48.87104,2.36610",
         "True"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>capacity</th>\n",
       "      <th>available_mechanical</th>\n",
       "      <th>available_electrical</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_geo</th>\n",
       "      <th>operative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Benjamin Godard - Victor Hugo</td>\n",
       "      <td>48.86598,2.27572</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>Andr√© Mazet - Saint-Andr√© des Arts</td>\n",
       "      <td>48.85376,2.33910</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Charonne - Robert et Sonia Delauney</td>\n",
       "      <td>48.85591,2.39257</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toudouze - Clauzel</td>\n",
       "      <td>48.87930,2.33736</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mairie du 12√®me</td>\n",
       "      <td>48.84086,2.38755</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>Harpe - Saint-Germain</td>\n",
       "      <td>48.85152,2.34367</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Jourdan - Stade Charl√©ty</td>\n",
       "      <td>48.81943,2.34334</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Jouffroy d'Abbans - Wagram</td>\n",
       "      <td>48.88197,2.30113</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>Guersant - Gouvion-Saint-Cyr</td>\n",
       "      <td>48.88288,2.28767</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-11-26T12:59Z</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Alibert - Jemmapes</td>\n",
       "      <td>48.87104,2.36610</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time  capacity  available_mechanical  available_electrical  \\\n",
       "0  2020-11-26T12:59Z        35                     4                     5   \n",
       "1  2020-11-26T12:59Z        55                    23                     4   \n",
       "2  2020-11-26T12:59Z        20                     0                     0   \n",
       "3  2020-11-26T12:59Z        21                     0                     1   \n",
       "4  2020-11-26T12:59Z        30                     3                     1   \n",
       "5  2020-11-26T12:59Z        46                    18                    10   \n",
       "6  2020-11-26T12:59Z        60                     5                     2   \n",
       "7  2020-11-26T12:59Z        40                    15                     1   \n",
       "8  2020-11-26T12:59Z        39                    12                     2   \n",
       "9  2020-11-26T12:59Z        60                     2                     2   \n",
       "\n",
       "                          station_name       station_geo  operative  \n",
       "0        Benjamin Godard - Victor Hugo  48.86598,2.27572       True  \n",
       "1   Andr√© Mazet - Saint-Andr√© des Arts  48.85376,2.33910       True  \n",
       "2  Charonne - Robert et Sonia Delauney  48.85591,2.39257       True  \n",
       "3                   Toudouze - Clauzel  48.87930,2.33736       True  \n",
       "4                      Mairie du 12√®me  48.84086,2.38755       True  \n",
       "5                Harpe - Saint-Germain  48.85152,2.34367       True  \n",
       "6             Jourdan - Stade Charl√©ty  48.81943,2.34334       True  \n",
       "7           Jouffroy d'Abbans - Wagram  48.88197,2.30113       True  \n",
       "8         Guersant - Gouvion-Saint-Cyr  48.88288,2.28767       True  \n",
       "9                   Alibert - Jemmapes  48.87104,2.36610       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es vacances :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "holiday_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_date",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "end_date",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "zones",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "description",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "a63e8930-f11e-4aa8-94a1-d2d3750e0ed2",
       "rows": [
        [
         "0",
         "2030-01-01 00:00:00",
         "1er janvier",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "2030-04-22 00:00:00",
         "Lundi de P√¢ques",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "2030-05-01 00:00:00",
         "1er mai",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "2030-05-08 00:00:00",
         "8 mai",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "2030-05-30 00:00:00",
         "Ascension",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "2030-06-10 00:00:00",
         "Lundi de Pentec√¥te",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "2030-07-14 00:00:00",
         "14 juillet",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "2030-08-15 00:00:00",
         "Assomption",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "8",
         "2030-11-01 00:00:00",
         "Toussaint",
         "holiday",
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "2030-11-11 00:00:00",
         "11 novembre",
         "holiday",
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>holiday_name</th>\n",
       "      <th>type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>zones</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030-01-01</td>\n",
       "      <td>1er janvier</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030-04-22</td>\n",
       "      <td>Lundi de P√¢ques</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2030-05-01</td>\n",
       "      <td>1er mai</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2030-05-08</td>\n",
       "      <td>8 mai</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030-05-30</td>\n",
       "      <td>Ascension</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2030-06-10</td>\n",
       "      <td>Lundi de Pentec√¥te</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2030-07-14</td>\n",
       "      <td>14 juillet</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2030-08-15</td>\n",
       "      <td>Assomption</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2030-11-01</td>\n",
       "      <td>Toussaint</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2030-11-11</td>\n",
       "      <td>11 novembre</td>\n",
       "      <td>holiday</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        holiday_name     type start_date end_date zones  \\\n",
       "0 2030-01-01         1er janvier  holiday        NaT      NaT   NaN   \n",
       "1 2030-04-22     Lundi de P√¢ques  holiday        NaT      NaT   NaN   \n",
       "2 2030-05-01             1er mai  holiday        NaT      NaT   NaN   \n",
       "3 2030-05-08               8 mai  holiday        NaT      NaT   NaN   \n",
       "4 2030-05-30           Ascension  holiday        NaT      NaT   NaN   \n",
       "5 2030-06-10  Lundi de Pentec√¥te  holiday        NaT      NaT   NaN   \n",
       "6 2030-07-14          14 juillet  holiday        NaT      NaT   NaN   \n",
       "7 2030-08-15          Assomption  holiday        NaT      NaT   NaN   \n",
       "8 2030-11-01           Toussaint  holiday        NaT      NaT   NaN   \n",
       "9 2030-11-11         11 novembre  holiday        NaT      NaT   NaN   \n",
       "\n",
       "  description  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es m√©t√©o :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_id",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "station_name",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "lat_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alt_m",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "precip_mm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precip_dur_min",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "temp_c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dewpoint_c",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "humidity_rel_pct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_speed_10m_ms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_dir_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_gust_10m_ms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pressure_hpa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cloud_oktas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "insolation_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "global_radiation_j_cm2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wmo_present_weather",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "81ff0cfd-4903-435a-8415-183c314e74d7",
       "rows": [
        [
         "0",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 00:00:00",
         "0.0",
         "0",
         "0.7",
         "-3.3",
         "74.0",
         "8.9",
         "140.0",
         "14.0",
         "1013.8",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 01:00:00",
         "0.0",
         "0",
         "0.9",
         "-3.3",
         "74.0",
         "9.7",
         "150.0",
         "14.7",
         "1013.1",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 02:00:00",
         "0.0",
         "0",
         "0.7",
         "-2.2",
         "81.0",
         "10.2",
         "140.0",
         "14.3",
         "1012.6",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 03:00:00",
         "0.0",
         "20",
         "0.8",
         "-2.2",
         "81.0",
         "11.5",
         "130.0",
         "16.5",
         "1011.0",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 04:00:00",
         "0.0",
         "0",
         "0.9",
         "-2.0",
         "82.0",
         "12.9",
         "120.0",
         "18.0",
         "1008.7",
         "8.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 05:00:00",
         "0.0",
         "10",
         "0.5",
         "-1.2",
         "89.0",
         "13.7",
         "120.0",
         "20.2",
         "1006.4",
         "8.0",
         "0.0",
         "0.0",
         "70.0"
        ],
        [
         "6",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 06:00:00",
         "0.0",
         "60",
         "0.6",
         "-0.5",
         "92.0",
         "14.0",
         "120.0",
         "22.3",
         "1005.0",
         "8.0",
         "0.0",
         "0.0",
         "68.0"
        ],
        [
         "7",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 07:00:00",
         "0.4",
         "60",
         "0.6",
         "0.0",
         "96.0",
         "14.6",
         "120.0",
         "22.1",
         "1003.6",
         "8.0",
         "0.0",
         "0.0",
         "68.0"
        ],
        [
         "8",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 08:00:00",
         "1.2",
         "60",
         "0.8",
         "0.2",
         "96.0",
         "15.0",
         "120.0",
         "23.6",
         "1001.7",
         "8.0",
         "0.0",
         "0.0",
         "68.0"
        ],
        [
         "9",
         "97502001",
         "ST-PIERRE",
         "46.766333",
         "-56.179167",
         "21",
         "2020-01-01 09:00:00",
         "5.1",
         "60",
         "0.9",
         "0.4",
         "97.0",
         "14.1",
         "110.0",
         "21.2",
         "1001.2",
         "8.0",
         "0.0",
         "0.0",
         "68.0"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>lat_deg</th>\n",
       "      <th>lon_deg</th>\n",
       "      <th>alt_m</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>precip_mm</th>\n",
       "      <th>precip_dur_min</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>dewpoint_c</th>\n",
       "      <th>humidity_rel_pct</th>\n",
       "      <th>wind_speed_10m_ms</th>\n",
       "      <th>wind_dir_deg</th>\n",
       "      <th>wind_gust_10m_ms</th>\n",
       "      <th>pressure_hpa</th>\n",
       "      <th>cloud_oktas</th>\n",
       "      <th>insolation_min</th>\n",
       "      <th>global_radiation_j_cm2</th>\n",
       "      <th>wmo_present_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>140.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1013.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>150.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>120.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>89.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>120.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>1006.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 07:00:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>120.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>1003.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>1001.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97502001</td>\n",
       "      <td>ST-PIERRE</td>\n",
       "      <td>46.766333</td>\n",
       "      <td>-56.179167</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-01-01 09:00:00</td>\n",
       "      <td>5.1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>1001.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id station_name    lat_deg    lon_deg  alt_m           timestamp  \\\n",
       "0   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 00:00:00   \n",
       "1   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 01:00:00   \n",
       "2   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 02:00:00   \n",
       "3   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 03:00:00   \n",
       "4   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 04:00:00   \n",
       "5   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 05:00:00   \n",
       "6   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 06:00:00   \n",
       "7   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 07:00:00   \n",
       "8   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 08:00:00   \n",
       "9   97502001    ST-PIERRE  46.766333 -56.179167     21 2020-01-01 09:00:00   \n",
       "\n",
       "   precip_mm  precip_dur_min  temp_c  dewpoint_c  humidity_rel_pct  \\\n",
       "0        0.0               0     0.7        -3.3              74.0   \n",
       "1        0.0               0     0.9        -3.3              74.0   \n",
       "2        0.0               0     0.7        -2.2              81.0   \n",
       "3        0.0              20     0.8        -2.2              81.0   \n",
       "4        0.0               0     0.9        -2.0              82.0   \n",
       "5        0.0              10     0.5        -1.2              89.0   \n",
       "6        0.0              60     0.6        -0.5              92.0   \n",
       "7        0.4              60     0.6         0.0              96.0   \n",
       "8        1.2              60     0.8         0.2              96.0   \n",
       "9        5.1              60     0.9         0.4              97.0   \n",
       "\n",
       "   wind_speed_10m_ms  wind_dir_deg  wind_gust_10m_ms  pressure_hpa  \\\n",
       "0                8.9         140.0              14.0        1013.8   \n",
       "1                9.7         150.0              14.7        1013.1   \n",
       "2               10.2         140.0              14.3        1012.6   \n",
       "3               11.5         130.0              16.5        1011.0   \n",
       "4               12.9         120.0              18.0        1008.7   \n",
       "5               13.7         120.0              20.2        1006.4   \n",
       "6               14.0         120.0              22.3        1005.0   \n",
       "7               14.6         120.0              22.1        1003.6   \n",
       "8               15.0         120.0              23.6        1001.7   \n",
       "9               14.1         110.0              21.2        1001.2   \n",
       "\n",
       "   cloud_oktas  insolation_min  global_radiation_j_cm2  wmo_present_weather  \n",
       "0          8.0             0.0                     0.0                  0.0  \n",
       "1          8.0             0.0                     0.0                  0.0  \n",
       "2          8.0             0.0                     0.0                  0.0  \n",
       "3          8.0             0.0                     0.0                  0.0  \n",
       "4          8.0             0.0                     0.0                  0.0  \n",
       "5          8.0             0.0                     0.0                 70.0  \n",
       "6          8.0             0.0                     0.0                 68.0  \n",
       "7          8.0             0.0                     0.0                 68.0  \n",
       "8          8.0             0.0                     0.0                 68.0  \n",
       "9          8.0             0.0                     0.0                 68.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "velib_historical_dataframe = VelibCsvReader().read_dataframe()\n",
    "print(\"Donn√©es V√©los :\")\n",
    "display(velib_historical_dataframe.head(10))\n",
    "\n",
    "holidays_instance = HolidaysAPI()\n",
    "public_holidays_dataframe = holidays_instance.fetch_public_holidays()\n",
    "vacations_dataframe = holidays_instance.fetch_school_vacations()\n",
    "public_holidays_dataframe[\"type\"] = \"holiday\"\n",
    "vacations_dataframe[\"type\"] = \"vacation\"\n",
    "calendar_dataframe = pd.concat([public_holidays_dataframe, vacations_dataframe], ignore_index=True)\n",
    "print(\"Donn√©es vacances :\")\n",
    "display(calendar_dataframe.head(10))\n",
    "\n",
    "weather_dataframe = WeatherCsvReader().read_standardized()\n",
    "print(\"Donn√©es m√©t√©o :\")\n",
    "display(weather_dataframe.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f7988",
   "metadata": {},
   "source": [
    "# Mod√©lisation des donn√©es\n",
    "## Fonctions de mod√©lisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c1bf5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Pr√©paration des donn√©es...\n",
      "‚öôÔ∏è Construction des features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29840\\2493534093.py:70: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"fill_rate\"] = (df[\"available_total\"] / df[\"capacity\"].replace(0, pd.NA)).fillna(0).clip(0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Seuils appliqu√©s: target_empty >= 0.83 | target_full >= 0.17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class FeatureBuilder:\n",
    "    def __init__(self, velib, weather, calendar):\n",
    "        self.velib = velib\n",
    "        self.weather = weather\n",
    "        self.calendar = calendar\n",
    "\n",
    "    def _preprocess(self, velib, weather, calendar):\n",
    "        \"\"\"Pr√©pare et fusionne les datasets (fusion horaire simple)\"\"\"\n",
    "        print(\"üßπ Pr√©paration des donn√©es...\")\n",
    "\n",
    "        # Nettoyage des dates (UTC)\n",
    "        weather[\"timestamp\"] = pd.to_datetime(weather[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "        velib[\"time\"] = pd.to_datetime(velib[\"time\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "        # Cl√© horaire\n",
    "        weather[\"ts_hour\"] = weather[\"timestamp\"].dt.floor(\"h\")\n",
    "        velib[\"ts_hour\"] = velib[\"time\"].dt.floor(\"h\")\n",
    "\n",
    "        # ===== Flags m√©t√©o tr√®s simples (0/1) =====\n",
    "        precip = pd.to_numeric(weather.get(\"precip_mm\", 0), errors=\"coerce\").fillna(0.0)\n",
    "        precip_dur = pd.to_numeric(weather.get(\"precip_dur_min\", 0), errors=\"coerce\").fillna(0.0)\n",
    "        ws = pd.to_numeric(weather.get(\"wind_speed_10m_ms\", 0), errors=\"coerce\").fillna(0.0)\n",
    "        wg = pd.to_numeric(weather.get(\"wind_gust_10m_ms\", 0), errors=\"coerce\").fillna(0.0)\n",
    "        cloud_oktas = pd.to_numeric(weather.get(\"cloud_oktas\", np.nan), errors=\"coerce\")\n",
    "\n",
    "        # R√®gles binaires\n",
    "        weather[\"pluie\"]  = ((precip >= 0.1) | (precip_dur >= 5)).astype(int)\n",
    "        weather[\"vent\"]   = ((ws >= 8.0) | (wg >= 10.8)).astype(int)\n",
    "        weather[\"soleil\"] = cloud_oktas.le(2).fillna(False).astype(int)\n",
    "        weather[\"nuage\"]  = cloud_oktas.ge(6).fillna(False).astype(int)\n",
    "\n",
    "        # 1 ligne par heure\n",
    "        weather_flags = (\n",
    "            weather.sort_values(\"timestamp\")\n",
    "                   .drop_duplicates(subset=[\"ts_hour\"], keep=\"last\")\n",
    "                   [[\"ts_hour\", \"pluie\", \"vent\", \"soleil\", \"nuage\"]]\n",
    "                   .copy()\n",
    "        )\n",
    "        weather_flags[[\"pluie\", \"vent\", \"soleil\", \"nuage\"]] = weather_flags[[\"pluie\", \"vent\", \"soleil\", \"nuage\"]].fillna(0).astype(int)\n",
    "\n",
    "        # Fusion m√©t√©o ‚Üî V√©lib\n",
    "        df = velib.merge(weather_flags, on=\"ts_hour\", how=\"left\")\n",
    "        for c in [\"pluie\", \"vent\", \"soleil\", \"nuage\"]:\n",
    "            if c not in df.columns:\n",
    "                df[c] = 0\n",
    "        df[[\"pluie\", \"vent\", \"soleil\", \"nuage\"]] = df[[\"pluie\", \"vent\", \"soleil\", \"nuage\"]].fillna(0).astype(int)\n",
    "\n",
    "        # Ajout calendrier\n",
    "        df[\"date\"] = df[\"time\"].dt.tz_convert(\"Europe/Paris\").dt.date\n",
    "        cal = calendar.copy()\n",
    "        cal[\"date\"] = pd.to_datetime(cal[\"start_date\"]).dt.date\n",
    "        cal[\"holiday_flag\"] = 1\n",
    "        df = df.merge(cal[[\"date\", \"holiday_flag\"]].drop_duplicates(), on=\"date\", how=\"left\")\n",
    "        df[\"holiday_flag\"] = df[\"holiday_flag\"].fillna(0).astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _feature_engineering(self, df):\n",
    "        \"\"\"Cr√©e des variables d√©riv√©es utiles pour la pr√©diction\"\"\"\n",
    "        print(\"‚öôÔ∏è Construction des features...\")\n",
    "\n",
    "        # TOTAL v√©los dispo & bornes libres\n",
    "        df[\"available_total\"] = df[\"available_mechanical\"].fillna(0) + df[\"available_electrical\"].fillna(0)\n",
    "        df[\"docks_available\"] = df[\"capacity\"].fillna(0) - df[\"available_total\"]\n",
    "\n",
    "        # Taux d'occupation\n",
    "        df[\"fill_rate\"] = (df[\"available_total\"] / df[\"capacity\"].replace(0, pd.NA)).fillna(0).clip(0, 1)\n",
    "\n",
    "        # ‚úÖ Calcul des ratios s√ªrs\n",
    "        ratio_empty = (df[\"docks_available\"] / df[\"capacity\"].replace(0, np.nan)).replace([np.inf, -np.inf], np.nan).fillna(0).clip(0, 1)\n",
    "        ratio_full = (df[\"available_total\"] / df[\"capacity\"].replace(0, np.nan)).replace([np.inf, -np.inf], np.nan).fillna(0).clip(0, 1)\n",
    "\n",
    "        # ‚úÖ D√©finition automatique des seuils (adapt√©s √† ta distribution)\n",
    "        empty_threshold = ratio_empty.quantile(0.70)  # stations avec beaucoup de place\n",
    "        full_threshold  = ratio_full.quantile(0.30)   # stations avec assez de v√©los\n",
    "\n",
    "        print(f\"üìè Seuils appliqu√©s: target_empty >= {empty_threshold:.2f} | target_full >= {full_threshold:.2f}\")\n",
    "\n",
    "        # ‚úÖ Cibles binaires √©quilibr√©es\n",
    "        df[\"target_empty\"] = (ratio_empty >= empty_threshold).astype(int)\n",
    "        df[\"target_full\"]  = (ratio_full >= full_threshold).astype(int)\n",
    "\n",
    "        # Heures / jours\n",
    "        df = df.sort_values([\"station_name\", \"time\"])\n",
    "        df[\"hour\"] = df[\"time\"].dt.hour\n",
    "        df[\"day_of_week\"] = df[\"time\"].dt.day_name()\n",
    "\n",
    "        # Moyenne glissante (3h) par station\n",
    "        df[\"rolling_fill_rate\"] = (\n",
    "            df.groupby(\"station_name\")[\"fill_rate\"].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "        # Week-end\n",
    "        df[\"is_weekend\"] = df[\"day_of_week\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Ex√©cution compl√®te du pipeline de feature engineering\"\"\"\n",
    "        merged = self._preprocess(self.velib, self.weather, self.calendar)\n",
    "        if merged is None:\n",
    "            raise RuntimeError(\"[FeatureBuilder.run] _preprocess a renvoy√© None (attendu: DataFrame).\")\n",
    "        features = self._feature_engineering(merged)\n",
    "        return features\n",
    "\n",
    "\n",
    "# üß™ Exemple d'ex√©cution\n",
    "feature_dataframe = FeatureBuilder(\n",
    "    velib_historical_dataframe,\n",
    "    weather_dataframe,\n",
    "    calendar_dataframe\n",
    ").run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56712983",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d6a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "43ac4025-d334-4c0f-90eb-7556c6a53574",
       "rows": [
        [
         "519",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "1916",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "3313",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "4710",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "6107",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "7504",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "8901",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "10298",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "11695",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "13092",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "14489",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "15886",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "17283",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "18680",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "20077",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "21474",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "22871",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "24268",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "25665",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "27062",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "28459",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "29856",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "31253",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "32650",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "34047",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "35444",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "36841",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "38238",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "39635",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "41032",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "42429",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "43826",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "45223",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "46620",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "48017",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "49414",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "50811",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "52208",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "53605",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "55002",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "56399",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "57796",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "59193",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "60590",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "61987",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "63384",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "64781",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "66178",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "67575",
         " Jean Bleuzen - Square du 11 Novembre"
        ],
        [
         "68972",
         " Jean Bleuzen - Square du 11 Novembre"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10986730
       }
      },
      "text/plain": [
       "519          Jean Bleuzen - Square du 11 Novembre\n",
       "1916         Jean Bleuzen - Square du 11 Novembre\n",
       "3313         Jean Bleuzen - Square du 11 Novembre\n",
       "4710         Jean Bleuzen - Square du 11 Novembre\n",
       "6107         Jean Bleuzen - Square du 11 Novembre\n",
       "                            ...                  \n",
       "10980677                          √éle de la Jatte\n",
       "10982075                          √éle de la Jatte\n",
       "10983473                          √éle de la Jatte\n",
       "10984872                          √éle de la Jatte\n",
       "10986271                          √éle de la Jatte\n",
       "Name: station_name, Length: 10986730, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultat = feature_dataframe[\"station_name\"].groupby(\"station_name\").count()\n",
    "\n",
    "display(resultat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import joblib\n",
    "\n",
    "\n",
    "class VelibSimpleModel:\n",
    "    \"\"\"\n",
    "    Mod√®le simple et lisible pour pr√©dire si une station sera vide/pleine.\n",
    "\n",
    "    Principes :\n",
    "    - Utilise uniquement les colonnes d√©j√† pr√©sentes dans votre DataFrame d'exemple\n",
    "      (pas de m√©t√©o, pas de mapping).\n",
    "    - Encodage temporel cyclique (√† partir de 'time').\n",
    "    - Imputation l√©g√®re + standardisation pour les num√©riques, OHE pour station_id.\n",
    "    - API courte: fit / predict_proba / predict_label / save / load\n",
    "    - Param√®tres regroup√©s en dict (to_config / from_config).\n",
    "    \"\"\"\n",
    "\n",
    "    # Colonnes de base attendues (selon votre DataFrame d'entr√©e)\n",
    "    BASE_NUM_SCALED: List[str] = [\n",
    "        # features temporelles\n",
    "        \"hour_ssin\", \"hour_ccos\", \"dow_sin\", \"dow_cos\", \"month\",\n",
    "    ]\n",
    "    BASE_BIN_PASSTHROUGH: List[str] = [\n",
    "        \"holiday_flag\", \"is_weekend\", \"operative\",\n",
    "        \"pluie\", \"vent\", \"soleil\", \"nuage\",\n",
    "    ]\n",
    "    BASE_CATEG: List[str] = [\"station_name\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_col: str = \"target_empty\",        # ou \"target_full\"\n",
    "        model_type: str = \"gb\",                  # \"gb\" ou \"logit\"\n",
    "        timezone: str = \"Europe/Paris\",\n",
    "        random_state: int = 42,\n",
    "        test_size: float = 0.2,\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "        print(\"[__init__] ‚Üí D√©but initialisation du mod√®le\")\n",
    "        self.target_col = target_col\n",
    "        self.model_type = model_type\n",
    "        self.timezone = timezone\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Objets entra√Æn√©s\n",
    "        self.feature_list_: List[str] = []\n",
    "        self.preprocessor_: Optional[ColumnTransformer] = None\n",
    "        self.pipeline_: Optional[Pipeline] = None\n",
    "        print(\"[__init__] ‚úì Fin initialisation du mod√®le\")\n",
    "\n",
    "    # ------------- Helpers ---------------\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_columns(df: pd.DataFrame, cols: List[str]) -> None:\n",
    "        print(\"[_ensure_columns] ‚Üí V√©rification des colonnes requises...\")\n",
    "        missing = [c for c in cols if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Colonnes manquantes: {missing}\")\n",
    "        print(\"[_ensure_columns] ‚úì Toutes les colonnes sont pr√©sentes.\")\n",
    "\n",
    "    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Ajoute hour/dow/month + encodage cyclique √† partir de la colonne 'time'.\n",
    "        On ne d√©pend pas des colonnes 'hour'/'day_of_week' existantes pour garder la logique simple et robuste.\n",
    "        \"\"\"\n",
    "        print(\"[_add_time_features] ‚Üí D√©but g√©n√©ration des features temporelles...\")\n",
    "        if \"time\" not in df.columns:\n",
    "            raise ValueError(\"La colonne 'time' est requise.\")\n",
    "        ts = pd.to_datetime(df[\"time\"], utc=True).dt.tz_convert(self.timezone)\n",
    "\n",
    "        out = df.copy()\n",
    "        out[\"hour\"] = ts.dt.hour\n",
    "        out[\"dow\"] = ts.dt.weekday     # 0 = lundi\n",
    "        out[\"month\"] = ts.dt.month\n",
    "\n",
    "        out[\"hour_ssin\"] = np.sin(2 * np.pi * out[\"hour\"] / 24)\n",
    "        out[\"hour_ccos\"] = np.cos(2 * np.pi * out[\"hour\"] / 24)\n",
    "        out[\"dow_sin\"]   = np.sin(2 * np.pi * out[\"dow\"] / 7)\n",
    "        out[\"dow_cos\"]   = np.cos(2 * np.pi * out[\"dow\"] / 7)\n",
    "        print(\"[_add_time_features] ‚úì Features temporelles ajout√©es.\")\n",
    "        return out\n",
    "\n",
    "    def _build_preprocessor(self) -> None:\n",
    "        \"\"\"\n",
    "        Pr√©processeur:\n",
    "        - Num√©riques (imputation m√©diane + standardisation)\n",
    "        - Binaires (imputation la plus fr√©quente, pas de scaling)\n",
    "        - Cat√©gorielles (OHE handle_unknown='ignore')\n",
    "        \"\"\"\n",
    "        print(\"[_build_preprocessor] ‚Üí Construction du pr√©processeur...\")\n",
    "        # Gestion valeurs manquantes + standardisation\n",
    "        num_pipe = Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\", StandardScaler()),\n",
    "        ])\n",
    "        # Gestion valeurs manquantes (pas scaler pour garder 0/1 lisible)\n",
    "        bin_pipe = Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ])\n",
    "        # Transforme variables cat√©gorielles en binaire\n",
    "        cat_pipe = Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")),\n",
    "            (\"ohe\", OneHotEncoder(\n",
    "                handle_unknown=\"ignore\",\n",
    "                dtype=np.float32,\n",
    "                sparse_output=True,\n",
    "            )),\n",
    "        ])\n",
    "\n",
    "        # Liste des features finales\n",
    "        self.feature_list_ = (\n",
    "            self.BASE_NUM_SCALED\n",
    "            + self.BASE_BIN_PASSTHROUGH\n",
    "            + self.BASE_CATEG\n",
    "        )\n",
    "\n",
    "        # Applique les 3 pipelines de transformation + drop autres colonnes\n",
    "        self.preprocessor_ = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", num_pipe, self.BASE_NUM_SCALED),\n",
    "                (\"bin\", bin_pipe, self.BASE_BIN_PASSTHROUGH),\n",
    "                (\"cat\", cat_pipe, self.BASE_CATEG),\n",
    "            ],\n",
    "            remainder=\"drop\",\n",
    "            sparse_threshold=1.0,\n",
    "        )\n",
    "        print(\"[_build_preprocessor] ‚úì Pr√©processeur construit.\")\n",
    "\n",
    "    def _prepare_features(\n",
    "        self, df: pd.DataFrame, with_target: bool\n",
    "    ) -> Tuple[pd.DataFrame, Optional[pd.Series]]:\n",
    "        \"\"\"\n",
    "        - Ajoute les features temporelles\n",
    "        - V√©rifie la pr√©sence des colonnes attendues\n",
    "        - Renvoie X (et y si with_target)\n",
    "        \"\"\"\n",
    "        print(\"[_prepare_features] ‚Üí Pr√©paration des features...\")\n",
    "        # Ajoute les features temporelles\n",
    "        df2 = self._add_time_features(df)\n",
    "\n",
    "        # Construire le pr√©processeur si pas encore fait\n",
    "        if self.preprocessor_ is None:\n",
    "            self._build_preprocessor()\n",
    "\n",
    "        # V√©rifier les colonnes d'entr√©e attendues\n",
    "        needed = (\n",
    "            set(self.BASE_NUM_SCALED + self.BASE_BIN_PASSTHROUGH + self.BASE_CATEG)\n",
    "            - {\"hour_ssin\", \"hour_ccos\", \"dow_sin\", \"dow_cos\", \"month\"}  # cr√©√©es ici\n",
    "        )\n",
    "        self._ensure_columns(df2, sorted(needed))\n",
    "\n",
    "        X = df2[self.feature_list_] # Liste de colonne cr√©√©e dans _build_preprocessor()\n",
    "\n",
    "        y = None\n",
    "        if with_target: # V√©rification de la pr√©sence de la colonne cible (√† pr√©dire)\n",
    "            if self.target_col not in df2.columns:\n",
    "                raise ValueError(f\"Colonne cible manquante: '{self.target_col}'\")\n",
    "            y = df2[self.target_col].astype(int)\n",
    "\n",
    "        # Renvoi les colonnes de param√®tre ainsi que la colonne cible \n",
    "        print(\"[_prepare_features] ‚úì Features pr√©par√©es.\")\n",
    "        return X, y\n",
    "\n",
    "    # ------------- API publique ---------------\n",
    "\n",
    "    def fit(self, df: pd.DataFrame) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Entra√Æne le mod√®le choisi et renvoie des m√©triques simples (AUC).\n",
    "        \"\"\"\n",
    "        print(\"[fit] ‚Üí D√©but entra√Ænement du mod√®le...\")\n",
    "        \n",
    "        self._build_preprocessor()# (r√©)initialise un pr√©processeur propre\n",
    "        X, y = self._prepare_features(df, with_target=True) # Pr√©paration des features\n",
    "\n",
    "        # Choix du classifieur\n",
    "        if self.model_type == \"logit\":\n",
    "            classifier = LogisticRegression(max_iter=300, solver=\"saga\", verbose=1, random_state=self.random_state)\n",
    "        else:\n",
    "            classifier = GradientBoostingClassifier(random_state=self.random_state, verbose=1)\n",
    "\n",
    "        # Assemblage pr√©processeur + classifieur\n",
    "        self.pipeline_ = Pipeline(steps=[(\"preprocessor\", self.preprocessor_), (\"classifier\", classifier)])\n",
    "\n",
    "        X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "            X, y,\n",
    "            test_size=self.test_size,\n",
    "            stratify=y,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "\n",
    "        print(\"[fit] ‚Üí Entra√Ænement en cours...\")\n",
    "        self.pipeline_.fit(X_tr, y_tr)\n",
    "\n",
    "        print(\"[fit] ‚úì Entra√Ænement termin√©. √âvaluation en cours...\")\n",
    "\n",
    "        proba = self.pipeline_.predict_proba(X_va)[:, 1]\n",
    "        y_pred = (proba >= 0.5).astype(int)  # seuil simple\n",
    "\n",
    "        acc = accuracy_score(y_va, y_pred)\n",
    "        f1  = f1_score(y_va, y_pred)\n",
    "\n",
    "        metrics = {\n",
    "            \"val_accuracy\": float(acc),\n",
    "            \"val_f1\": float(f1),\n",
    "            \"n_samples_train\": int(len(X_tr)),\n",
    "            \"n_samples_val\": int(len(X_va)),\n",
    "        }\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"[{self.target_col}] {self.model_type.upper()}  \"\n",
    "                f\"ACC={metrics['val_accuracy']:.3f}  F1={metrics['val_f1']:.3f}  \"\n",
    "                f\"(train={metrics['n_samples_train']}, val={metrics['n_samples_val']})\")\n",
    "\n",
    "\n",
    "        print(\"[fit] ‚úì Fin de l'entra√Ænement et des m√©triques.\")\n",
    "        return metrics\n",
    "\n",
    "    def predict_proba(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Probabilit√© d'√™tre positif (ex: vide si target_empty).\"\"\"\n",
    "        print(\"[predict_proba] ‚Üí D√©but pr√©diction des probabilit√©s...\")\n",
    "        check_is_fitted(self.pipeline_, \"named_steps\")\n",
    "        # NE PAS reconstruire le pr√©processeur ici\n",
    "        X, _ = self._prepare_features(df, with_target=False)\n",
    "        print(\"[predict_proba] ‚úì Fin pr√©diction des probabilit√©s.\")\n",
    "        return self.pipeline_.predict_proba(X)[:, 1]\n",
    "\n",
    "    def predict_label(self, df: pd.DataFrame, threshold: float = 0.5) -> pd.Series:\n",
    "        \"\"\"Label binaire selon un seuil.\"\"\"\n",
    "        print(\"[predict_label] ‚Üí D√©but pr√©diction des labels...\")\n",
    "        p = self.predict_proba(df)\n",
    "        print(\"[predict_label] ‚úì Fin pr√©diction des labels.\")\n",
    "        return pd.Series((p >= threshold).astype(int), index=df.index, name=f\"{self.target_col}_pred\")\n",
    "\n",
    "    def save(self, path: str) -> None:\n",
    "        \"\"\"Sauvegarde le pipeline complet (pr√©traitement + mod√®le).\"\"\"\n",
    "        print(\"[save] ‚Üí Sauvegarde du mod√®le...\")\n",
    "        check_is_fitted(self.pipeline_, \"named_steps\")\n",
    "        joblib.dump(self.pipeline_, path)\n",
    "        print(\"[save] ‚úì Mod√®le sauvegard√©.\")\n",
    "\n",
    "    def load(self, path: str) -> None:\n",
    "        \"\"\"Charge un pipeline entra√Æn√© (pr√©processeur inclus).\"\"\"\n",
    "        print(\"[load] ‚Üí Chargement du mod√®le...\")\n",
    "        self.pipeline_ = joblib.load(path)\n",
    "        # on r√©cup√®re le pr√©processeur et la liste de features du pipeline sauvegard√©\n",
    "        if hasattr(self.pipeline_, \"named_steps\") and \"preprocessor\" in self.pipeline_.named_steps:\n",
    "            self.preprocessor_ = self.pipeline_.named_steps[\"preprocessor\"]\n",
    "        # La feature_list_ est utile seulement pour _prepare_features (ordre des colonnes en entr√©e)\n",
    "        # On la reconstruit √† partir des attributs de classe pour rester d√©terministe :\n",
    "        self.feature_list_ = (\n",
    "            self.BASE_NUM_SCALED + self.BASE_BIN_PASSTHROUGH + self.BASE_CATEG\n",
    "        )\n",
    "        print(\"[load] ‚úì Mod√®le charg√© avec succ√®s.\")\n",
    "\n",
    "    # --------- Config dict ---------\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, cfg: Dict) -> \"VelibSimpleModel\":\n",
    "        print(\"[from_config] ‚Üí Cr√©ation du mod√®le depuis un dictionnaire de config...\")\n",
    "        model = cls(**cfg)\n",
    "        print(\"[from_config] ‚úì Mod√®le cr√©√© depuis la config.\")\n",
    "        return model\n",
    "\n",
    "    def to_config(self) -> Dict:\n",
    "        print(\"[to_config] ‚Üí Export de la configuration du mod√®le...\")\n",
    "        cfg = {\n",
    "            \"target_col\": self.target_col,\n",
    "            \"model_type\": self.model_type,\n",
    "            \"timezone\": self.timezone,\n",
    "            \"random_state\": self.random_state,\n",
    "            \"test_size\": self.test_size,\n",
    "            \"verbose\": self.verbose,\n",
    "        }\n",
    "        print(\"[to_config] ‚úì Configuration export√©e.\")\n",
    "        return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb6b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[from_config] ‚Üí Cr√©ation du mod√®le depuis un dictionnaire de config...\n",
      "[__init__] ‚Üí D√©but initialisation du mod√®le\n",
      "[__init__] ‚úì Fin initialisation du mod√®le\n",
      "[from_config] ‚úì Mod√®le cr√©√© depuis la config.\n",
      "[fit] ‚Üí D√©but entra√Ænement du mod√®le...\n",
      "[_build_preprocessor] ‚Üí Construction du pr√©processeur...\n",
      "[_build_preprocessor] ‚úì Pr√©processeur construit.\n",
      "[_prepare_features] ‚Üí Pr√©paration des features...\n",
      "[_add_time_features] ‚Üí D√©but g√©n√©ration des features temporelles...\n",
      "[_add_time_features] ‚úì Features temporelles ajout√©es.\n",
      "[_ensure_columns] ‚Üí V√©rification des colonnes requises...\n",
      "[_ensure_columns] ‚úì Toutes les colonnes sont pr√©sentes.\n",
      "[_prepare_features] ‚úì Features pr√©par√©es.\n",
      "[fit] ‚Üí Entra√Ænement en cours...\n",
      "convergence after 216 epochs took 1767 seconds\n",
      "[fit] ‚úì Entra√Ænement termin√©. √âvaluation en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 29.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target_full] LOGIT  ACC=0.777  F1=0.851  (train=8789384, val=2197346)\n",
      "[fit] ‚úì Fin de l'entra√Ænement et des m√©triques.\n",
      "üìä R√©sultats de l'entra√Ænement :\n",
      "  - val_accuracy: 0.7769035918785663\n",
      "  - val_f1: 0.8512563802098346\n",
      "  - n_samples_train: 8789384\n",
      "  - n_samples_val: 2197346\n",
      "[save] ‚Üí Sauvegarde du mod√®le...\n",
      "[save] ‚úì Mod√®le sauvegard√©.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Charger vos donn√©es\n",
    "df = feature_dataframe # pd.read_csv(\"velib_data.csv\")  # ou df = votre_dataframe d√©j√† charg√©\n",
    "\n",
    "# 2. Cr√©er le mod√®le avec vos param√®tres\n",
    "config = {\n",
    "    \"target_col\": \"target_full\",     # ou \"target_full\"\n",
    "    \"model_type\": \"logit\",               # \"gb\" ou \"logit\"\n",
    "    \"timezone\": \"Europe/Paris\",\n",
    "    \"random_state\": 42,\n",
    "    \"test_size\": 0.2,\n",
    "    \"verbose\": True\n",
    "}\n",
    "model = VelibSimpleModel.from_config(config)\n",
    "\n",
    "# 3. Lancer l'entra√Ænement\n",
    "metrics = model.fit(feature_dataframe)\n",
    "\n",
    "# 4. Afficher les r√©sultats\n",
    "print(\"üìä R√©sultats de l'entra√Ænement :\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "# 5. (Optionnel) Sauvegarder le mod√®le\n",
    "model.save(\"target_full.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
